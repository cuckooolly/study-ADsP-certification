# 빅데이터의 이해
## 1. 빅데이터의 이해
### 1. 다양한 빅데이터 정의 및 특성
1. 규모 중심 정의
   - 일반적인 데이터베시스 소프트웨어로 저장, 관리, 분석할 수 있는 범위를 초과하는 규모의 데이터
2. 분석 비용 및 기술 초점 정의
   - 다양한 종류의 대규모 데이터로부터 저렴한 비용으로 가치를 추출하고 데이터의 초고속 수집, 발굴, 분석을 지원하도록 고안된 차세대 기술 및 아키텍처 
3. 빅데이터의 특성 "3V"
   - Volume (양): 데이터의 용량, 물리적인 크기가 커지고 있다.
   - Variety (다양성): 다양한 유형의 데이터가 생성, 저장되고 있다.
   - Velocity (속도): 수집과 처리, 활용 과정에서 속도가 빨라지고 주기가 단축되고 있다.

## 2. 빅데이터의 출현 배경 및 영향
### 1. 빅데이터 출현 배경
1. 데이터 산업의 진화
   - 거래를 정확하게 기록하고 거래의 자동화를 지원하는 데이터 처리 및 통합 중심의 비즈니스에서 더 많은 데이터를 연결하고 활용하며 분석하는 비즈니스로 확장되었다.
2. 비즈니스 데이터의 축적
   - 3차 산업혁명으로 불리는 IT 기술의 지속적인 발전 및 다양한 IT 비즈니스의 성장으로 다양한 산업 영역에 걸쳐 데이터의 지속적인 축적이 이뤄졌다.
   - 스마트 디바이스의 보급이 가속화되면서, SNS 등의 플랫폼 비즈니스가 성장하였으며, 플랫폼을 중심으로 고객/콘텐츠/거래 등 다양하고 규모가 큰 데이터가 쌓이게 되었다.
3. 데이터 관련 기술의 발전
   - 데이터 처리 및 저장에 필요한 기술의 발달로, 시간이 지날수록 더 많은 데이터를 더 낮은 비용으로 처리/저장/활용 할 수 있게 되었다
   - 인터넷과 다양한 센서가 통합된 스마트 디바이스의 보급으로 실시간으로 더 많은 데이터가 생성되고 네트워크를 통해 이동할 수 있는 환경이 조성되었다.
   - 새로운 기술은 기존 플랫폼의 기술적 한계를 극복하고 더 많은 트래픽과 데이터를 처리할 수 있도록 도움
4. 데이터 및 알고리즘 기반 연구 활발
   - 다양한 학계에서 데이터 처리와 분석을 위한 알고리즘을 개발해왔으며, 더 많은 데이터와 더 빠른 컴퓨터 성능을 활용해 고도화된 알고리즘을 개발하고 데이터 기술 발달에 기여함
   - 비즈니스 영역에서 적재된 데이터를 활용하여 정보를 추출하고 가치를 창출하기 위한 다양한 전략과 방법을 모색했듯이, 다양한 연구 영역에서도 기존보다 더 크고 복잡한 데이터에서 알고리즘을 활용해 정보를 고도화하는 방법이 일반화되고 있다.

### 2. 빅데이터 영향
1. 빅데이터 관심 증가
   - 빅데이터는 차세대 산업 혁신에 꼭 필요한 요소로 관심이 집중되고 있다
2. 빅데이터 영향 증대
   - 데이터의 중요성과 네트워크를 활용한 데이터의 이동, 알고리즘을 활용한 데이터의 활용 전략이 강조되고 있다.
   - 다양한 주체별로 빅데이터에 대한 관심과 투자가 확대되고 있다.
   - 정교한 상황 분석을 통한 고도화된 전략 수립을 통해 혁신과 경쟁력 제고, 생산성 향상 등 미래 대응에 힘쓰고 있음.

### 3. 데이터 분석 방향 진화

- 데이터 분석 영역에서도 빅데이터는 분석 전략 수립, 분석 방법, 분석 수행 절차 등에 큰 영향을 미친다.
- "주제 설정 -> 실험 계획 -> 실험 및 데이터 수집 -> 데이터 처리 -> 분석 -> 결과 도출"의 단계로 진행되는 데이터 연구는 4가지 본질적인 변화를 겪었다.

1. 사전 처리 -> **사후 처리**
   - 기존에는 실험 계획을 통해서 분석에 필요한 데이터만 수집하고, 수집된 데이터에서 불필요한 부분을 제거하는 사전 처리가 중요했음
   - 빅데이터는 실험 계획과 상관없이 운영 과정에서 수집되는 경우가 많으며, 이미 적재된 데이터와 현재 상황에 맞게 분석 주제를 설정하고 데이터를 처리하는 사후 처리가 필요하다.
   - 분석 주체 설정이 데이터 적재 이후에 이뤄지면서 데이터 처리 시점에 차이가 발생한다.
2. 표본조사 -> **전수조사**
   - 실험이나 설문조사에는 데이터 수집과 관련된 비용이 들기 때문에 실험을 무한히 반복하거나 관심 대상 전부를 조사하는 전수조사가 어렵고, 실험 횟수를 제한하거나 일부 대상을 조사하는 표본 조사가 일반적이였다.
   - 이미 쌓여 있는 빅데이터를 활용해서 분석을 수행할 경우, 별도의 데이터 수집이 필요 없고, 적재된 데이터 전부를 모두 활용한 분석이 가능하다.
   - 빅데이터 분석은 일종의 전수조사라고 볼 수 있으나, 데이터베이스에 모든 데이터가 들어 있지는 않으므로 주의가 필요하다.
3. 질 -> **양**
   - 데이터 처리와 분석과정에서 충분한 컴퓨팅 자원이 있다면, 더 많은 데이터를 활용하는 것이 오류를 낮추고 성능을 높이며 더 나은 분석 결과를 가져오는 경우가 많다.
   - 단, 실제 분석에서는 아무리 큰 데이터라 하더라도 분석에 적합하지 않은 부분 데이터를 제거하는 등 데이터의 질을 높이기 위한 작업이 선행되어야 한다.
4. 인과관계 -> **상관관계**
   - 기존에는 통제 기법을 활용하여 데이터를 수집하여 인과관계를 해석하기엔 무리가 있었다.
   - 대부분의 빅데이터는 분석주제에 따라서 계획되지 않고 통제되지 않은 상태로 적재되기 때문에, 데이터의 어떤 변수 혹은 요인들 간의 상관관계나 패턴 등을 일반화하여 인과관계로 확장하기가 어렵다.
   - 빅데이터 분석을 통해 얻은 정보와 인사이트를 바탕으로 전략을 수립하고 실행한 후 다시 쌓인 데이터를 활용해 정보와 전략을 개선/업데이트하는 방법이 일반화되고 있다.

## 3. 빅데이터의 위기 요인과 통제 방안
1. 위기 요인
   1. 사생활 침해
      - 개인정보가 유출될 경우, 개인의 사생활이 침해될 우려가 있다.
   2. 책임 원칙 훼손
      - 실생활과 밀접한 의사결정과정에서 알고리즘 활용이 일반화되면서, 특정 개인의 행동이나 특성이 아닌 개인이 속한 집단에 따라 예측이 이뤄지고 결과가 정해지는 문제가 발생할 수 있다.
      - 개인의 잘못이 아님에도 불이익을 받는 책임 원칙 훼손이 발생하면서 사회 정의 문제로 이어질 수 있다.
   3. 데이터 오용
      - 오류와 불확실성에 대한 이해가 없는 데이터 및 알고리즘에 대한 맹목적인 믿음은 잘못된 의사결정과 피해로 이어질 수 있다.
2. 통제 방안
   1. 동의제에서 책임제로 전환
      - 데이터로 인한 사생활 침해 문제를 해결하기 위해, 개인정보 제공자의 동의보다 사용자의 책임을 강조하는 방안을 통해 사용 주체가 보다 적극적인 개인정보 보호 장치를 강구할 수 있도록 유도할 수 있다???
   2. 결과 기반 책임 원칙 고수
      - 사법판단에서 특정인의 성향 등을 고려한 알고리즘의 예측이 아닌 실제 결과를 바탕으로 책임을 부여하는 원칙을 유지한다.
   3. 알고리즘 접근 허용
      - 무분별한 알고리즘 활용 및 적용으로 인한 데이터 오용 및 부작용을 최소화하기 위해 알고리즘에 대한 접근권을 보장하고 객관적인 인증방안을 도입할 필요가 있다.